{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d85f2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "# ==========================================\n",
    "# 0. ダミーデータの生成\n",
    "# (お手元のデータがある場合はここをスキップし、CSVを読み込んでください)\n",
    "# ==========================================\n",
    "def generate_suzuri_dummy_data(n_users=1000, n_creators=50, n_transactions=5000):\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # --- 1. クリエイターテーブル作成 ---\n",
    "    creators = []\n",
    "    for i in range(n_creators):\n",
    "        creators.append({\n",
    "            'creator_id': i,\n",
    "            'name': f'creator_{i}',\n",
    "            'display_name': f'Display_Creator_{i}',\n",
    "            'created_at': '2020-01-01',\n",
    "            'official': np.random.choice([True, False], p=[0.1, 0.9]),\n",
    "            'bio': 'Sample bio...'\n",
    "        })\n",
    "    df_creators = pd.DataFrame(creators)\n",
    "    \n",
    "    # クリエイターごとの「画風・世界観」ベクトル (128次元) を擬似的に作成\n",
    "    # 実際は material_url の画像をCNNに通して得られるベクトルなどを想定\n",
    "    creator_visual_features = np.random.rand(n_creators, 128)\n",
    "\n",
    "    # --- 2. トランザクションデータ作成 ---\n",
    "    data = []\n",
    "    actions = ['view', 'add_to_cart', 'purchase', 'favorite']\n",
    "    categories = ['T-shirt', 'Hoodie', 'Sticker', 'Smartphone Case', 'Tote Bag']\n",
    "    \n",
    "    start_date = datetime(2025, 1, 1)\n",
    "    \n",
    "    for _ in range(n_transactions):\n",
    "        user_id = np.random.randint(0, n_users)\n",
    "        \n",
    "        # Whale (太客) バイアス: ID 0~9 は購入頻度が高く、同じものを買いがち\n",
    "        is_whale = user_id < 10\n",
    "        \n",
    "        # アクション決定 (Whaleはpurchase率が高いとする)\n",
    "        if is_whale:\n",
    "            action = np.random.choice(actions, p=[0.1, 0.1, 0.7, 0.1])\n",
    "        else:\n",
    "            action = np.random.choice(actions, p=[0.5, 0.2, 0.1, 0.2])\n",
    "            \n",
    "        # 日時 (ランダムな1年間)\n",
    "        days_offset = np.random.randint(0, 365)\n",
    "        accessed_at = start_date + timedelta(days=days_offset)\n",
    "        month = accessed_at.month\n",
    "        \n",
    "        # クリエイターとアイテム決定\n",
    "        creator_id = np.random.randint(0, n_creators)\n",
    "        product_id = f\"prod_{creator_id}_{np.random.randint(0, 5)}\"\n",
    "        \n",
    "        # カテゴリ決定 (季節性を反映)\n",
    "        if 4 <= month <= 8: # 夏\n",
    "            cat_name = np.random.choice(categories, p=[0.5, 0.1, 0.2, 0.1, 0.1])\n",
    "        else: # 冬\n",
    "            cat_name = np.random.choice(categories, p=[0.1, 0.5, 0.2, 0.1, 0.1])\n",
    "            \n",
    "        # 価格決定\n",
    "        price_map = {'T-shirt': 3000, 'Hoodie': 5000, 'Sticker': 500, 'Smartphone Case': 2500, 'Tote Bag': 2000}\n",
    "        price = price_map[cat_name]\n",
    "        \n",
    "        # Whaleは大量買いする (購入の場合、同じログを複数回入れるか、売上計算で考慮)\n",
    "        # ここではシンプルに1行1購入とし、Whaleは何回もループを回っているとする\n",
    "        \n",
    "        row = {\n",
    "            'user_id': user_id,\n",
    "            'accessed_at': accessed_at, # datetime型\n",
    "            'event_action': action,\n",
    "            'product_id': product_id,\n",
    "            'creator_name': f'creator_{creator_id}',\n",
    "            'creator_id': creator_id,\n",
    "            'title': f'Title {product_id}',\n",
    "            'description': 'desc',\n",
    "            'item_id': f'item_{product_id}',\n",
    "            'item_name': f'Item {cat_name}',\n",
    "            'item_category_id': 999,\n",
    "            'item_category_name': cat_name,\n",
    "            'exemplary_item_color_id': 1,\n",
    "            'exemplary_item_color_name': 'White',\n",
    "            'material_1': 123, # material ID\n",
    "            'material_url': 'http://example.com/img.jpg',\n",
    "            'sale_1': 0, # 簡略化\n",
    "            'profit': price * 0.1,\n",
    "            'price': price\n",
    "        }\n",
    "        data.append(row)\n",
    "        \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df, df_creators, creator_visual_features\n",
    "\n",
    "# データを生成\n",
    "df, df_creators, creator_features = generate_suzuri_dummy_data()\n",
    "\n",
    "# ==========================================\n",
    "# 前処理: データの型変換とフィルタリング\n",
    "# ==========================================\n",
    "# 実際のCSV読み込み時はここで to_datetime 変換を行ってください\n",
    "df['accessed_at'] = pd.to_datetime(df['accessed_at'])\n",
    "\n",
    "# 分析用データの作成 (購入ログのみ)\n",
    "df_purchase = df[df['event_action'] == 'purchase'].copy()\n",
    "print(f\"Total Transactions: {len(df)}\")\n",
    "print(f\"Total Purchases: {len(df_purchase)}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 分析1: Whale汚染度の検証 (売上金額 vs 購入人数)\n",
    "# ==========================================\n",
    "print(\"\\n--- [Analysis 1] Whale Impact Check ---\")\n",
    "\n",
    "# プロダクトごとの「総売上金額」と「ユニーク購入者数(UU)」を集計\n",
    "item_stats = df_purchase.groupby('product_id').agg(\n",
    "    total_revenue=('price', 'sum'),\n",
    "    unique_users=('user_id', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "# Top 30 ランキングの作成\n",
    "top_revenue = item_stats.sort_values('total_revenue', ascending=False).head(30)['product_id'].values\n",
    "top_uu = item_stats.sort_values('unique_users', ascending=False).head(30)['product_id'].values\n",
    "\n",
    "# ランキングの乖離率 (Jaccard Distance)\n",
    "intersection = len(set(top_revenue) & set(top_uu))\n",
    "overlap_rate = intersection / 30\n",
    "churn_rate = 1.0 - overlap_rate\n",
    "\n",
    "print(f\"Top 30 Overlap Rate (金額ランク vs 人数ランク): {overlap_rate:.2f}\")\n",
    "print(f\"Ranking Churn Rate (入れ替わり率): {churn_rate:.2f}\")\n",
    "\n",
    "# ジニ係数の計算 (アイテムごとの購入者の偏り)\n",
    "# 特定のアイテムの購入者分布を見て、少数が買い占めていないか確認\n",
    "# ※ここでは全アイテム平均の簡易チェックを行う\n",
    "def calc_gini(array):\n",
    "    array = array.flatten()\n",
    "    if np.amin(array) < 0: return -1 # マイナス値は不可\n",
    "    array = np.sort(array)\n",
    "    index = np.arange(1, array.shape[0] + 1)\n",
    "    n = array.shape[0]\n",
    "    return ((np.sum((2 * index - n - 1) * array)) / (n * np.sum(array)))\n",
    "\n",
    "# 最も売上の高いアイテムを抽出してジニ係数を計算\n",
    "top_item = item_stats.sort_values('total_revenue', ascending=False).iloc[0]['product_id']\n",
    "top_item_buyers = df_purchase[df_purchase['product_id'] == top_item].groupby('user_id')['price'].sum().values\n",
    "gini_score = calc_gini(top_item_buyers) if len(top_item_buyers) > 1 else 0\n",
    "\n",
    "print(f\"Gini Coefficient of Top Item ('{top_item}'): {gini_score:.2f}\")\n",
    "\n",
    "if churn_rate >= 0.3 or gini_score > 0.6:\n",
    "    print(\">> JUDGMENT: GO (一部のユーザーによる売上依存度が高く、Whale対策が必要です)\")\n",
    "else:\n",
    "    print(\">> JUDGMENT: CAUTION (売上は比較的広く分散しています)\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 分析2: 探索のポテンシャル (クリエイター類似度 vs 併売数)\n",
    "# ==========================================\n",
    "print(\"\\n--- [Analysis 2] Exploration Potential ---\")\n",
    "\n",
    "# 1. クリエイター間の併売行列 (Co-occurrence)\n",
    "# user_id x creator_id の行列を作る\n",
    "user_creator_matrix = pd.crosstab(df_purchase['user_id'], df_purchase['creator_id'])\n",
    "user_creator_matrix[user_creator_matrix > 0] = 1 # 購入有無(0/1)にする\n",
    "co_occurrence_matrix = user_creator_matrix.T.dot(user_creator_matrix)\n",
    "\n",
    "# 2. クリエイター間の画像類似度 (本来は material_url の画像解析結果を使用)\n",
    "visual_sim_matrix = cosine_similarity(creator_features)\n",
    "\n",
    "# 3. データの結合 (類似度と併売数のペアを作る)\n",
    "plot_data = []\n",
    "creators_list = list(co_occurrence_matrix.index)\n",
    "# 計算量削減のためサンプリングまたはループ最適化推奨。ここでは全ペア実施\n",
    "for i in range(len(creators_list)):\n",
    "    for j in range(i + 1, len(creators_list)):\n",
    "        c1, c2 = creators_list[i], creators_list[j]\n",
    "        sim = visual_sim_matrix[c1, c2] # 画像類似度\n",
    "        co_count = co_occurrence_matrix.iloc[i, j] # 併売数\n",
    "        plot_data.append({'similarity': sim, 'co_purchase': co_count})\n",
    "\n",
    "df_plot = pd.DataFrame(plot_data)\n",
    "\n",
    "# 類似度ごとにビン分割して、平均併売数を計算\n",
    "df_plot['sim_bin'] = pd.cut(df_plot['similarity'], bins=10)\n",
    "bin_stats = df_plot.groupby('sim_bin', observed=False)['co_purchase'].mean()\n",
    "\n",
    "print(\"Similarity Bins vs Avg Co-purchase:\")\n",
    "print(bin_stats)\n",
    "\n",
    "# 可視化\n",
    "plt.figure(figsize=(10, 5))\n",
    "bin_centers = np.arange(0.05, 1.05, 0.1)\n",
    "plt.plot(bin_centers, bin_stats.values, marker='o', linestyle='-')\n",
    "plt.title('Visual Similarity vs Co-Purchase Count')\n",
    "plt.xlabel('Similarity (Low -> High)')\n",
    "plt.ylabel('Avg Co-Purchases')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 判断ロジック: 中程度の類似度(0.4-0.7)の山があるか？\n",
    "mid_sim_avg = bin_stats.iloc[4:7].mean() # 0.4~0.7\n",
    "high_sim_avg = bin_stats.iloc[8:].mean() # 0.8~1.0\n",
    "if mid_sim_avg > high_sim_avg:\n",
    "    print(\">> JUDGMENT: GO (『似すぎない』クリエイター同士の併売が多く、探索レコメンドの余地があります)\")\n",
    "else:\n",
    "    print(\">> JUDGMENT: NEUTRAL (類似度と併売数が比例、またはランダムです)\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 分析3: LTV/離脱率のインパクト (金額ベース)\n",
    "# ==========================================\n",
    "print(\"\\n--- [Analysis 3] LTV Impact (Single vs Multi Creator) ---\")\n",
    "\n",
    "# ユーザーごとの統計\n",
    "user_stats = df_purchase.groupby('user_id').agg(\n",
    "    unique_creators=('creator_id', 'nunique'),\n",
    "    ltv=('price', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# グループ分け\n",
    "single_creator_users = user_stats[user_stats['unique_creators'] == 1]\n",
    "multi_creator_users = user_stats[user_stats['unique_creators'] >= 2]\n",
    "\n",
    "ltv_single = single_creator_users['ltv'].mean()\n",
    "ltv_multi = multi_creator_users['ltv'].mean()\n",
    "\n",
    "uplift = ltv_multi / ltv_single if ltv_single > 0 else 0\n",
    "\n",
    "print(f\"Avg LTV (Single Creator): ¥{ltv_single:,.0f}\")\n",
    "print(f\"Avg LTV (Multi Creator):  ¥{ltv_multi:,.0f}\")\n",
    "print(f\"LTV Uplift: {uplift:.2f}x\")\n",
    "\n",
    "if uplift >= 1.5:\n",
    "    print(\">> JUDGMENT: GO (複数クリエイター推しのユーザーはLTVが圧倒的に高いです)\")\n",
    "else:\n",
    "    print(\">> JUDGMENT: CAUTION (単推しと複数推しでLTVに大きな差がありません)\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 分析4: 季節性の遷移 (accessed_at ベース)\n",
    "# ==========================================\n",
    "print(\"\\n--- [Analysis 4] Seasonal Category Transition ---\")\n",
    "\n",
    "# 日付順にソート\n",
    "df_sorted = df_purchase.sort_values(['user_id', 'accessed_at'])\n",
    "\n",
    "# 月カラムの作成\n",
    "df_sorted['month'] = df_sorted['accessed_at'].dt.month\n",
    "\n",
    "# 次に買った商品のカテゴリを取得\n",
    "df_sorted['next_category'] = df_sorted.groupby('user_id')['item_category_name'].shift(-1)\n",
    "\n",
    "# 「夏(4-8月)にT-shirtを買った人」の次の購入\n",
    "summer_tshirt_users = df_sorted[\n",
    "    (df_sorted['month'].between(4, 8)) & \n",
    "    (df_sorted['item_category_name'] == 'T-shirt')\n",
    "]\n",
    "\n",
    "# 遷移先を集計\n",
    "if len(summer_tshirt_users) > 0:\n",
    "    transition_probs = summer_tshirt_users['next_category'].value_counts(normalize=True)\n",
    "    print(\"Transition from Summer T-shirt:\")\n",
    "    print(transition_probs.head())\n",
    "    \n",
    "    # 判断: ランダム(20%)より明らかに高い遷移先があるか\n",
    "    top_prob = transition_probs.iloc[0]\n",
    "    if top_prob > 0.3:\n",
    "        print(\">> JUDGMENT: GO (特定のカテゴリへの遷移傾向が見られ、RNN等の時系列モデルが有効です)\")\n",
    "    else:\n",
    "        print(\">> JUDGMENT: NEUTRAL (次の購入カテゴリは分散しています)\")\n",
    "else:\n",
    "    print(\"データ不足のため季節性分析をスキップしました\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe7df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "import warnings\n",
    "\n",
    "# 警告の抑制（バージョンによるFutureWarning対策）\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. データの準備 (ダミーデータ生成)\n",
    "# ※実際はここに csv 読み込み処理を入れてください: df = pd.read_csv('data.csv')\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# カラム定義（ご提示いただいたデータセットに準拠）\n",
    "data = {\n",
    "    'user_id': [1, 1, 1, 2, 2, 3, 3, 3, 4, 1],\n",
    "    'product_id': [101, 102, 103, 101, 104, 105, 106, 105, 107, 101],\n",
    "    'event_action': [\n",
    "        'view', 'add_to_cart', 'purchase',  # User 1\n",
    "        'view', 'view',                     # User 2\n",
    "        'purchase', 'favorite', 'view',     # User 3\n",
    "        'view',                             # User 4\n",
    "        'view'                              # User 1 (再閲覧)\n",
    "    ],\n",
    "    # 他のカラムは今回の計算には使用しませんが、存在するものとします\n",
    "    'accessed_at': pd.date_range(start='2024-01-01', periods=10),\n",
    "    'price': [3000] * 10\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"--- 元データ（先頭5行） ---\")\n",
    "print(df[['user_id', 'product_id', 'event_action']].head())\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. アクションの重み付け (Score Mapping)\n",
    "# ---------------------------------------------------------\n",
    "# viewを有効活用しつつ、purchaseの重要度を高く設定します。\n",
    "# remove_from_cart は興味がなくなったと判断し、マイナススコアで相殺します。\n",
    "\n",
    "event_weights = {\n",
    "    'purchase': 10,          # 購入（最強のシグナル）\n",
    "    'checkout': 8,           # 購入直前\n",
    "    'add_to_cart': 5,        # 強い興味\n",
    "    'add_to_wishlist': 3,    # 保存\n",
    "    'favorite': 3,           # いいね\n",
    "    'view': 1,               # 閲覧（弱いシグナルだが数が重要）\n",
    "    'remove_from_cart': -5   # カート削除（興味の減衰）\n",
    "}\n",
    "\n",
    "# event_action を数値スコアに変換\n",
    "df['event_score'] = df['event_action'].map(event_weights).fillna(0)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. ユーザー×プロダクトごとのスコア集計 (Aggregation)\n",
    "# ---------------------------------------------------------\n",
    "# 同じユーザーが同じプロダクトに対して行ったアクションを合計します。\n",
    "# 例: view(1) * 5回 + add_to_cart(5) = 10点\n",
    "grouped_df = df.groupby(['user_id', 'product_id'])['event_score'].sum().reset_index()\n",
    "\n",
    "# マイナスになったスコア（カート削除などで）は0（無関心）としてクリッピング\n",
    "grouped_df['event_score'] = grouped_df['event_score'].clip(lower=0)\n",
    "\n",
    "# スコアが0のものは除外（疎行列化のため）\n",
    "grouped_df = grouped_df[grouped_df['event_score'] > 0]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. 対数変換 (Log Transformation) - 重要！\n",
    "# ---------------------------------------------------------\n",
    "# 「ある一人のユーザーの大量購入」や「異常な閲覧回数」によるバイアスを抑える処理です。\n",
    "# 生の回数 N を log(1 + N) に変換し、極端な値をマイルドにします。\n",
    "grouped_df['event_score'] = np.log1p(grouped_df['event_score'])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. IDのマッピング (Encoding)\n",
    "# ---------------------------------------------------------\n",
    "# user_id, product_id を 0 から始まる連番（インデックス）に変換\n",
    "user_ids = grouped_df['user_id'].unique()\n",
    "product_ids = grouped_df['product_id'].unique()\n",
    "\n",
    "user_to_index = {uid: i for i, uid in enumerate(user_ids)}\n",
    "product_to_index = {pid: i for i, pid in enumerate(product_ids)}\n",
    "\n",
    "# 逆引き用辞書（推薦結果を元のIDに戻すため）\n",
    "index_to_user = {i: uid for i, uid in enumerate(user_ids)}\n",
    "index_to_product = {i: pid for i, pid in enumerate(product_ids)}\n",
    "\n",
    "grouped_df['user_index'] = grouped_df['user_id'].map(user_to_index)\n",
    "grouped_df['product_index'] = grouped_df['product_id'].map(product_to_index)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 6. 疎行列 (CSR Matrix) の作成\n",
    "# ---------------------------------------------------------\n",
    "# implicitライブラリ用の行列作成 (rows=user, cols=item)\n",
    "sparse_user_item = sparse.csr_matrix(\n",
    "    (grouped_df['event_score'].astype(float),\n",
    "     (grouped_df['user_index'], grouped_df['product_index'])),\n",
    "    shape=(len(user_ids), len(product_ids))\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 7. モデル学習 (ALS with Implicit Feedback)\n",
    "# ---------------------------------------------------------\n",
    "# factors: 次元数（特徴量の数）。データが多い場合は 64~128 程度に増やす。\n",
    "# alpha: 信頼度係数。これが高いほど「アクションした事実」を重く見る。\n",
    "model = AlternatingLeastSquares(\n",
    "    factors=32,\n",
    "    regularization=0.1,\n",
    "    iterations=20,\n",
    "    alpha=15,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 学習実行\n",
    "# sparse_user_item 行列を渡します\n",
    "model.fit(sparse_user_item)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 8. 推薦の実行と結果表示\n",
    "# ---------------------------------------------------------\n",
    "def recommend_for_user(target_user_id, n_items=10):\n",
    "    if target_user_id not in user_to_index:\n",
    "        print(f\"User ID {target_user_id} は学習データに存在しません（コールドスタート）。\")\n",
    "        return\n",
    "\n",
    "    user_idx = user_to_index[target_user_id]\n",
    "    \n",
    "    # 推薦実行\n",
    "    # filter_already_liked_items=True: 既にアクションした商品は除外（新規発見を優先）\n",
    "    # Falseにすると「リピート購入」も推薦に含まれるようになります\n",
    "    ids, scores = model.recommend(\n",
    "        user_idx, \n",
    "        sparse_user_item[user_idx], \n",
    "        N=n_items, \n",
    "        filter_already_liked_items=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nUser ID: {target_user_id} への推薦結果:\")\n",
    "    for i, score in zip(ids, scores):\n",
    "        original_product_id = index_to_product[i]\n",
    "        print(f\" - Product ID: {original_product_id} (Score: {score:.4f})\")\n",
    "\n",
    "# テスト実行（User ID 1 に対して）\n",
    "recommend_for_user(target_user_id=1, n_items=10)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
