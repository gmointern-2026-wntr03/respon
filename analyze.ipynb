{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d85f2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "# ==========================================\n",
    "# 0. ダミーデータの生成\n",
    "# (お手元のデータがある場合はここをスキップし、CSVを読み込んでください)\n",
    "# ==========================================\n",
    "def generate_suzuri_dummy_data(n_users=1000, n_creators=50, n_transactions=5000):\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # --- 1. クリエイターテーブル作成 ---\n",
    "    creators = []\n",
    "    for i in range(n_creators):\n",
    "        creators.append({\n",
    "            'creator_id': i,\n",
    "            'name': f'creator_{i}',\n",
    "            'display_name': f'Display_Creator_{i}',\n",
    "            'created_at': '2020-01-01',\n",
    "            'official': np.random.choice([True, False], p=[0.1, 0.9]),\n",
    "            'bio': 'Sample bio...'\n",
    "        })\n",
    "    df_creators = pd.DataFrame(creators)\n",
    "    \n",
    "    # クリエイターごとの「画風・世界観」ベクトル (128次元) を擬似的に作成\n",
    "    # 実際は material_url の画像をCNNに通して得られるベクトルなどを想定\n",
    "    creator_visual_features = np.random.rand(n_creators, 128)\n",
    "\n",
    "    # --- 2. トランザクションデータ作成 ---\n",
    "    data = []\n",
    "    actions = ['view', 'add_to_cart', 'purchase', 'favorite']\n",
    "    categories = ['T-shirt', 'Hoodie', 'Sticker', 'Smartphone Case', 'Tote Bag']\n",
    "    \n",
    "    start_date = datetime(2025, 1, 1)\n",
    "    \n",
    "    for _ in range(n_transactions):\n",
    "        user_id = np.random.randint(0, n_users)\n",
    "        \n",
    "        # Whale (太客) バイアス: ID 0~9 は購入頻度が高く、同じものを買いがち\n",
    "        is_whale = user_id < 10\n",
    "        \n",
    "        # アクション決定 (Whaleはpurchase率が高いとする)\n",
    "        if is_whale:\n",
    "            action = np.random.choice(actions, p=[0.1, 0.1, 0.7, 0.1])\n",
    "        else:\n",
    "            action = np.random.choice(actions, p=[0.5, 0.2, 0.1, 0.2])\n",
    "            \n",
    "        # 日時 (ランダムな1年間)\n",
    "        days_offset = np.random.randint(0, 365)\n",
    "        accessed_at = start_date + timedelta(days=days_offset)\n",
    "        month = accessed_at.month\n",
    "        \n",
    "        # クリエイターとアイテム決定\n",
    "        creator_id = np.random.randint(0, n_creators)\n",
    "        product_id = f\"prod_{creator_id}_{np.random.randint(0, 5)}\"\n",
    "        \n",
    "        # カテゴリ決定 (季節性を反映)\n",
    "        if 4 <= month <= 8: # 夏\n",
    "            cat_name = np.random.choice(categories, p=[0.5, 0.1, 0.2, 0.1, 0.1])\n",
    "        else: # 冬\n",
    "            cat_name = np.random.choice(categories, p=[0.1, 0.5, 0.2, 0.1, 0.1])\n",
    "            \n",
    "        # 価格決定\n",
    "        price_map = {'T-shirt': 3000, 'Hoodie': 5000, 'Sticker': 500, 'Smartphone Case': 2500, 'Tote Bag': 2000}\n",
    "        price = price_map[cat_name]\n",
    "        \n",
    "        # Whaleは大量買いする (購入の場合、同じログを複数回入れるか、売上計算で考慮)\n",
    "        # ここではシンプルに1行1購入とし、Whaleは何回もループを回っているとする\n",
    "        \n",
    "        row = {\n",
    "            'user_id': user_id,\n",
    "            'accessed_at': accessed_at, # datetime型\n",
    "            'event_action': action,\n",
    "            'product_id': product_id,\n",
    "            'creator_name': f'creator_{creator_id}',\n",
    "            'creator_id': creator_id,\n",
    "            'title': f'Title {product_id}',\n",
    "            'description': 'desc',\n",
    "            'item_id': f'item_{product_id}',\n",
    "            'item_name': f'Item {cat_name}',\n",
    "            'item_category_id': 999,\n",
    "            'item_category_name': cat_name,\n",
    "            'exemplary_item_color_id': 1,\n",
    "            'exemplary_item_color_name': 'White',\n",
    "            'material_1': 123, # material ID\n",
    "            'material_url': 'http://example.com/img.jpg',\n",
    "            'sale_1': 0, # 簡略化\n",
    "            'profit': price * 0.1,\n",
    "            'price': price\n",
    "        }\n",
    "        data.append(row)\n",
    "        \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df, df_creators, creator_visual_features\n",
    "\n",
    "# データを生成\n",
    "df, df_creators, creator_features = generate_suzuri_dummy_data()\n",
    "\n",
    "# ==========================================\n",
    "# 前処理: データの型変換とフィルタリング\n",
    "# ==========================================\n",
    "# 実際のCSV読み込み時はここで to_datetime 変換を行ってください\n",
    "df['accessed_at'] = pd.to_datetime(df['accessed_at'])\n",
    "\n",
    "# 分析用データの作成 (購入ログのみ)\n",
    "df_purchase = df[df['event_action'] == 'purchase'].copy()\n",
    "print(f\"Total Transactions: {len(df)}\")\n",
    "print(f\"Total Purchases: {len(df_purchase)}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 分析1: Whale汚染度の検証 (売上金額 vs 購入人数)\n",
    "# ==========================================\n",
    "print(\"\\n--- [Analysis 1] Whale Impact Check ---\")\n",
    "\n",
    "# プロダクトごとの「総売上金額」と「ユニーク購入者数(UU)」を集計\n",
    "item_stats = df_purchase.groupby('product_id').agg(\n",
    "    total_revenue=('price', 'sum'),\n",
    "    unique_users=('user_id', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "# Top 30 ランキングの作成\n",
    "top_revenue = item_stats.sort_values('total_revenue', ascending=False).head(30)['product_id'].values\n",
    "top_uu = item_stats.sort_values('unique_users', ascending=False).head(30)['product_id'].values\n",
    "\n",
    "# ランキングの乖離率 (Jaccard Distance)\n",
    "intersection = len(set(top_revenue) & set(top_uu))\n",
    "overlap_rate = intersection / 30\n",
    "churn_rate = 1.0 - overlap_rate\n",
    "\n",
    "print(f\"Top 30 Overlap Rate (金額ランク vs 人数ランク): {overlap_rate:.2f}\")\n",
    "print(f\"Ranking Churn Rate (入れ替わり率): {churn_rate:.2f}\")\n",
    "\n",
    "# ジニ係数の計算 (アイテムごとの購入者の偏り)\n",
    "# 特定のアイテムの購入者分布を見て、少数が買い占めていないか確認\n",
    "# ※ここでは全アイテム平均の簡易チェックを行う\n",
    "def calc_gini(array):\n",
    "    array = array.flatten()\n",
    "    if np.amin(array) < 0: return -1 # マイナス値は不可\n",
    "    array = np.sort(array)\n",
    "    index = np.arange(1, array.shape[0] + 1)\n",
    "    n = array.shape[0]\n",
    "    return ((np.sum((2 * index - n - 1) * array)) / (n * np.sum(array)))\n",
    "\n",
    "# 最も売上の高いアイテムを抽出してジニ係数を計算\n",
    "top_item = item_stats.sort_values('total_revenue', ascending=False).iloc[0]['product_id']\n",
    "top_item_buyers = df_purchase[df_purchase['product_id'] == top_item].groupby('user_id')['price'].sum().values\n",
    "gini_score = calc_gini(top_item_buyers) if len(top_item_buyers) > 1 else 0\n",
    "\n",
    "print(f\"Gini Coefficient of Top Item ('{top_item}'): {gini_score:.2f}\")\n",
    "\n",
    "if churn_rate >= 0.3 or gini_score > 0.6:\n",
    "    print(\">> JUDGMENT: GO (一部のユーザーによる売上依存度が高く、Whale対策が必要です)\")\n",
    "else:\n",
    "    print(\">> JUDGMENT: CAUTION (売上は比較的広く分散しています)\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 分析2: 探索のポテンシャル (クリエイター類似度 vs 併売数)\n",
    "# ==========================================\n",
    "print(\"\\n--- [Analysis 2] Exploration Potential ---\")\n",
    "\n",
    "# 1. クリエイター間の併売行列 (Co-occurrence)\n",
    "# user_id x creator_id の行列を作る\n",
    "user_creator_matrix = pd.crosstab(df_purchase['user_id'], df_purchase['creator_id'])\n",
    "user_creator_matrix[user_creator_matrix > 0] = 1 # 購入有無(0/1)にする\n",
    "co_occurrence_matrix = user_creator_matrix.T.dot(user_creator_matrix)\n",
    "\n",
    "# 2. クリエイター間の画像類似度 (本来は material_url の画像解析結果を使用)\n",
    "visual_sim_matrix = cosine_similarity(creator_features)\n",
    "\n",
    "# 3. データの結合 (類似度と併売数のペアを作る)\n",
    "plot_data = []\n",
    "creators_list = list(co_occurrence_matrix.index)\n",
    "# 計算量削減のためサンプリングまたはループ最適化推奨。ここでは全ペア実施\n",
    "for i in range(len(creators_list)):\n",
    "    for j in range(i + 1, len(creators_list)):\n",
    "        c1, c2 = creators_list[i], creators_list[j]\n",
    "        sim = visual_sim_matrix[c1, c2] # 画像類似度\n",
    "        co_count = co_occurrence_matrix.iloc[i, j] # 併売数\n",
    "        plot_data.append({'similarity': sim, 'co_purchase': co_count})\n",
    "\n",
    "df_plot = pd.DataFrame(plot_data)\n",
    "\n",
    "# 類似度ごとにビン分割して、平均併売数を計算\n",
    "df_plot['sim_bin'] = pd.cut(df_plot['similarity'], bins=10)\n",
    "bin_stats = df_plot.groupby('sim_bin', observed=False)['co_purchase'].mean()\n",
    "\n",
    "print(\"Similarity Bins vs Avg Co-purchase:\")\n",
    "print(bin_stats)\n",
    "\n",
    "# 可視化\n",
    "plt.figure(figsize=(10, 5))\n",
    "bin_centers = np.arange(0.05, 1.05, 0.1)\n",
    "plt.plot(bin_centers, bin_stats.values, marker='o', linestyle='-')\n",
    "plt.title('Visual Similarity vs Co-Purchase Count')\n",
    "plt.xlabel('Similarity (Low -> High)')\n",
    "plt.ylabel('Avg Co-Purchases')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 判断ロジック: 中程度の類似度(0.4-0.7)の山があるか？\n",
    "mid_sim_avg = bin_stats.iloc[4:7].mean() # 0.4~0.7\n",
    "high_sim_avg = bin_stats.iloc[8:].mean() # 0.8~1.0\n",
    "if mid_sim_avg > high_sim_avg:\n",
    "    print(\">> JUDGMENT: GO (『似すぎない』クリエイター同士の併売が多く、探索レコメンドの余地があります)\")\n",
    "else:\n",
    "    print(\">> JUDGMENT: NEUTRAL (類似度と併売数が比例、またはランダムです)\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 分析3: LTV/離脱率のインパクト (金額ベース)\n",
    "# ==========================================\n",
    "print(\"\\n--- [Analysis 3] LTV Impact (Single vs Multi Creator) ---\")\n",
    "\n",
    "# ユーザーごとの統計\n",
    "user_stats = df_purchase.groupby('user_id').agg(\n",
    "    unique_creators=('creator_id', 'nunique'),\n",
    "    ltv=('price', 'sum')\n",
    ").reset_index()\n",
    "\n",
    "# グループ分け\n",
    "single_creator_users = user_stats[user_stats['unique_creators'] == 1]\n",
    "multi_creator_users = user_stats[user_stats['unique_creators'] >= 2]\n",
    "\n",
    "ltv_single = single_creator_users['ltv'].mean()\n",
    "ltv_multi = multi_creator_users['ltv'].mean()\n",
    "\n",
    "uplift = ltv_multi / ltv_single if ltv_single > 0 else 0\n",
    "\n",
    "print(f\"Avg LTV (Single Creator): ¥{ltv_single:,.0f}\")\n",
    "print(f\"Avg LTV (Multi Creator):  ¥{ltv_multi:,.0f}\")\n",
    "print(f\"LTV Uplift: {uplift:.2f}x\")\n",
    "\n",
    "if uplift >= 1.5:\n",
    "    print(\">> JUDGMENT: GO (複数クリエイター推しのユーザーはLTVが圧倒的に高いです)\")\n",
    "else:\n",
    "    print(\">> JUDGMENT: CAUTION (単推しと複数推しでLTVに大きな差がありません)\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 分析4: 季節性の遷移 (accessed_at ベース)\n",
    "# ==========================================\n",
    "print(\"\\n--- [Analysis 4] Seasonal Category Transition ---\")\n",
    "\n",
    "# 日付順にソート\n",
    "df_sorted = df_purchase.sort_values(['user_id', 'accessed_at'])\n",
    "\n",
    "# 月カラムの作成\n",
    "df_sorted['month'] = df_sorted['accessed_at'].dt.month\n",
    "\n",
    "# 次に買った商品のカテゴリを取得\n",
    "df_sorted['next_category'] = df_sorted.groupby('user_id')['item_category_name'].shift(-1)\n",
    "\n",
    "# 「夏(4-8月)にT-shirtを買った人」の次の購入\n",
    "summer_tshirt_users = df_sorted[\n",
    "    (df_sorted['month'].between(4, 8)) & \n",
    "    (df_sorted['item_category_name'] == 'T-shirt')\n",
    "]\n",
    "\n",
    "# 遷移先を集計\n",
    "if len(summer_tshirt_users) > 0:\n",
    "    transition_probs = summer_tshirt_users['next_category'].value_counts(normalize=True)\n",
    "    print(\"Transition from Summer T-shirt:\")\n",
    "    print(transition_probs.head())\n",
    "    \n",
    "    # 判断: ランダム(20%)より明らかに高い遷移先があるか\n",
    "    top_prob = transition_probs.iloc[0]\n",
    "    if top_prob > 0.3:\n",
    "        print(\">> JUDGMENT: GO (特定のカテゴリへの遷移傾向が見られ、RNN等の時系列モデルが有効です)\")\n",
    "    else:\n",
    "        print(\">> JUDGMENT: NEUTRAL (次の購入カテゴリは分散しています)\")\n",
    "else:\n",
    "    print(\"データ不足のため季節性分析をスキップしました\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
